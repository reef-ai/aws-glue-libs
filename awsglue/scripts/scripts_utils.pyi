from pyspark.sql.types import *
from pyspark.sql.functions import *
from awsglue.context import GlueContext as GlueContext
from awsglue.dynamicframe import DynamicFrame as DynamicFrame
from awsglue.transforms import get_transform as get_transform

COLLECT_RESULT_NAME: str
DEFAULT_CATALOG_ENDPOINT: str
DEFAULT_GLUE_ENDPOINT: str
DEFAULT_REGION: str

def write_backup(data, database_name, backup_location, glue_context) -> None: ...
def nest_data_frame(data_frame, database_name, entity_type): ...
def write_df_to_catalog(data_frame, entity_type, glue_context, options) -> None: ...
def catalog_dict(data_frame): ...
def read_from_catalog(glue_context, options): ...
def write_df_to_s3(glue_context, data_frame, backup_location) -> None: ...
def read_from_s3(glue_context, backup_location): ...
