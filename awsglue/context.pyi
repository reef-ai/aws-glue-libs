from awsglue.data_sink import DataSink as DataSink
from awsglue.data_source import DataSource as DataSource
from awsglue.dataframereader import DataFrameReader as DataFrameReader
from awsglue.dynamicframe import DynamicFrame as DynamicFrame, DynamicFrameCollection as DynamicFrameCollection, DynamicFrameReader as DynamicFrameReader, DynamicFrameWriter as DynamicFrameWriter
from awsglue.gluetypes import DataType as DataType
from awsglue.streaming_data_source import StreamingDataSource as StreamingDataSource
from awsglue.utils import callsite as callsite, makeOptions as makeOptions
from pyspark.sql import SQLContext
from pyspark.sql.utils import StreamingQueryException as StreamingQueryException
from typing import Any

def register(sc) -> None: ...

class GlueContext(SQLContext):
    Spark_SQL_Formats: Any
    create_dynamic_frame: Any
    create_data_frame: Any
    write_dynamic_frame: Any
    spark_session: Any
    def __init__(self, sparkContext, **options) -> None: ...
    def getSource(self, connection_type, format: Any | None = ..., transformation_ctx: str = ..., push_down_predicate: str = ..., **options): ...
    def getStreamingSource(self, connection_type, format: Any | None = ..., transformation_ctx: str = ..., push_down_predicate: str = ..., **options): ...
    def get_catalog_schema_as_spark_schema(self, database: Any | None = ..., table_name: Any | None = ..., catalog_id: Any | None = ...): ...
    def create_dynamic_frame_from_rdd(self, data, name, schema: Any | None = ..., sample_ratio: Any | None = ..., transformation_ctx: str = ...): ...
    def create_dynamic_frame_from_catalog(self, database: Any | None = ..., table_name: Any | None = ..., redshift_tmp_dir: str = ..., transformation_ctx: str = ..., push_down_predicate: str = ..., additional_options=..., catalog_id: Any | None = ..., **kwargs): ...
    def create_data_frame_from_catalog(self, database: Any | None = ..., table_name: Any | None = ..., redshift_tmp_dir: str = ..., transformation_ctx: str = ..., push_down_predicate: str = ..., additional_options=..., catalog_id: Any | None = ..., **kwargs): ...
    def create_dynamic_frame_from_options(self, connection_type, connection_options=..., format: Any | None = ..., format_options=..., transformation_ctx: str = ..., push_down_predicate: str = ..., **kwargs): ...
    def create_data_frame_from_options(self, connection_type, connection_options=..., format: Any | None = ..., format_options=..., transformation_ctx: str = ..., push_down_predicate: str = ..., **kwargs): ...
    def getSink(self, connection_type, format: Any | None = ..., transformation_ctx: str = ..., **options): ...
    def write_dynamic_frame_from_options(self, frame, connection_type, connection_options=..., format: Any | None = ..., format_options=..., transformation_ctx: str = ...): ...
    def write_from_options(self, frame_or_dfc, connection_type, connection_options=..., format=..., format_options=..., transformation_ctx: str = ..., **kwargs): ...
    def write_dynamic_frame_from_catalog(self, frame, database: Any | None = ..., table_name: Any | None = ..., redshift_tmp_dir: str = ..., transformation_ctx: str = ..., additional_options=..., catalog_id: Any | None = ..., **kwargs): ...
    def write_dynamic_frame_from_jdbc_conf(self, frame, catalog_connection, connection_options=..., redshift_tmp_dir: str = ..., transformation_ctx: str = ..., catalog_id: Any | None = ...) -> None: ...
    def write_from_jdbc_conf(self, frame_or_dfc, catalog_connection, connection_options=..., redshift_tmp_dir: str = ..., transformation_ctx: str = ..., catalog_id: Any | None = ...): ...
    def convert_resolve_option(self, path, action, target): ...
    def extract_jdbc_conf(self, connection_name, catalog_id: Any | None = ...): ...
    def purge_table(self, database, table_name, options=..., transformation_ctx: str = ..., catalog_id: Any | None = ...) -> None: ...
    def purge_s3_path(self, s3_path, options=..., transformation_ctx: str = ...) -> None: ...
    def transition_table(self, database, table_name, transition_to, options=..., transformation_ctx: str = ..., catalog_id: Any | None = ...) -> None: ...
    def transition_s3_path(self, s3_path, transition_to, options=..., transformation_ctx: str = ...) -> None: ...
    def get_logger(self): ...
    def currentTimeMillis(self): ...
    def forEachBatch(self, frame, batch_function, options=...) -> None: ...
    def add_ingestion_time_columns(self, frame, time_granularity): ...
    def begin_transaction(self, read_only): ...
    def commit_transaction(self, transaction_id): ...
    def abort_transaction(self, transaction_id): ...
